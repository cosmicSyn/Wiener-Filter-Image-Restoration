{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f4c5830-0132-4ee3-b205-ed5045ab887a",
      "metadata": {
        "id": "4f4c5830-0132-4ee3-b205-ed5045ab887a"
      },
      "source": [
        "# EE 605 Digital Image Processing\n",
        "# Assignment_3\n",
        "#### -Karan Khajanchi (21110096)\n",
        "## Image Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81272ee-9cd7-4be4-aeff-b000a1055f90",
      "metadata": {
        "id": "f81272ee-9cd7-4be4-aeff-b000a1055f90"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e933ec-ecb1-419d-9028-e39cd51c15d3",
      "metadata": {
        "id": "b3e933ec-ecb1-419d-9028-e39cd51c15d3"
      },
      "outputs": [],
      "source": [
        "def plot_image(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5031310f-8731-4b4d-9847-9efc330527b1",
      "metadata": {
        "id": "5031310f-8731-4b4d-9847-9efc330527b1"
      },
      "outputs": [],
      "source": [
        "image1 = cv2.imread(\"Dataset\\image1.png\")\n",
        "image2 = cv2.imread(\"Dataset\\image2.png\")\n",
        "image3 = cv2.imread(\"Dataset\\image3.png\")\n",
        "image4 = cv2.imread(\"Dataset\\image4.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c6e0ae-f168-4664-8bfc-1adc3387c49e",
      "metadata": {
        "id": "44c6e0ae-f168-4664-8bfc-1adc3387c49e"
      },
      "source": [
        "Using some OpenCV functions, we define a function to add defocus blur and noise to an image. The function takes the following inputs:\n",
        "- image = original image.\n",
        "- ksigma = standard deviation for the gaussian kernel.\n",
        "- nsigma = standard deviation for the gaussian noise.\n",
        "- ksize = size of the kernel, the size of the 2D kernel will be (ksize)*(ksize)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72120e0-7c3f-429a-bd4b-0de4e675e018",
      "metadata": {
        "id": "c72120e0-7c3f-429a-bd4b-0de4e675e018"
      },
      "outputs": [],
      "source": [
        "def use_openCV(image,sigma, ksize):\n",
        "    # Create a circular defocus kernel\n",
        "    defocus_kernel = cv2.getGaussianKernel(ksize, sigma)\n",
        "\n",
        "    # Normalize the kernel to make sure the intensity values sum to 1\n",
        "    defocus_kernel = defocus_kernel / defocus_kernel.sum()\n",
        "\n",
        "    # Apply the circular defocus kernel using builtin filter2D function which convolves the kernel with the image\n",
        "    # Since the Gaussian filter is separable, the 2d gaussian kernel can be written as matrix multiplication of A and A'(transpose), where A is the 1D Gaussian\n",
        "    blurred_image = cv2.filter2D(image, -1, defocus_kernel * defocus_kernel.T)\n",
        "\n",
        "    # Add Gaussian noise to the blurred image\n",
        "    noise = np.random.normal(0, sigma, image.shape).astype(np.uint8) #mean is set to zero\n",
        "    final_img = np.clip(blurred_image + noise, 0, 255)\n",
        "\n",
        "    return final_img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "553ab700-6ec8-49ba-91a2-1071fb4847c4",
      "metadata": {
        "id": "553ab700-6ec8-49ba-91a2-1071fb4847c4"
      },
      "source": [
        "Now, we will define functions to perform above operations without OpenCV functions. <br>\n",
        "First, we define a function to add Gaussian noise to any image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38ce9af-7dbe-40bf-ab38-12925add4734",
      "metadata": {
        "id": "a38ce9af-7dbe-40bf-ab38-12925add4734"
      },
      "outputs": [],
      "source": [
        "def add_gaussian_noise(image, std=25):\n",
        "    # Numpy function to get random normal matrix\n",
        "    noise = np.random.normal(0, std, image.shape).astype(np.uint8)\n",
        "    # Add noise to the image\n",
        "    noisy_image = np.clip(image + noise, 0, 255)\n",
        "\n",
        "    return noisy_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f20c3f-a410-484c-a835-55b6e0a8373d",
      "metadata": {
        "id": "e0f20c3f-a410-484c-a835-55b6e0a8373d"
      },
      "source": [
        "Next, we need a function to compute the Gaussian kernel of a given size. For this we use the circularly symmetric gaussian function given as:<br>\n",
        "$K(x,y) = C exp (-(x^2 + y^2)/2 \\sigma^2)$ <br>\n",
        "The size of the 2D kernel will size*size (where size is given as input, along with the standard deviation of the Gaussian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f9c9f2b-8999-4d3b-9389-6e38d2019180",
      "metadata": {
        "id": "5f9c9f2b-8999-4d3b-9389-6e38d2019180"
      },
      "outputs": [],
      "source": [
        "def get_gaussian_kernel_2d(size, sigma):\n",
        "    kernel = np.fromfunction(\n",
        "        # The mathematical function used is given above\n",
        "        lambda x, y: (1/(2*np.pi*sigma**2)) * np.exp(-((x - (size-1)/2)**2 + (y - (size-1)/2)**2) / (2*sigma**2)),\n",
        "        (size, size),\n",
        "        dtype=np.float64\n",
        "    )\n",
        "    return kernel / np.sum(kernel) # Normalize the kernel before returning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e1297a-044b-4b55-89e8-9958b1283a2c",
      "metadata": {
        "id": "01e1297a-044b-4b55-89e8-9958b1283a2c"
      },
      "source": [
        "Next we define a function to perform convolution of the kernel with the image. This is a simple implementation using for-loops. For each pixel in the image we have to take one-to-one product of the elements of the kernel and the pixels neighbourhood region. For doing this we also need to pad the image around the edges to handle edge cases or boundary effects. Also, note that this is done for all the three channels (RGB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87227ca8-fa03-4662-bb84-1daa288213ed",
      "metadata": {
        "id": "87227ca8-fa03-4662-bb84-1daa288213ed"
      },
      "outputs": [],
      "source": [
        "def convolve(image, kernel, ksize):\n",
        "    # Get the dimensions of the image\n",
        "    n = len(image)\n",
        "    m = len(image[0])\n",
        "    # Getting the width that we need to pad on all four sides, which is half of the kernel size\n",
        "    r = ksize//2\n",
        "    # Initiliaze the final image with zeros\n",
        "    final_img = np.zeros_like(image)\n",
        "    # Pad the images to avoid boundary effects\n",
        "    padded_img = np.pad(image, ((r,r), (r,r), (0, 0)), mode='reflect')\n",
        "\n",
        "    # For each point in the image, keep the kernel centered at that point and take the onr-to-onr product of the kernel and image and place the sum in the image\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            for k in range(3):\n",
        "                x,y,z = i+r, j+r, k\n",
        "                sum = 0\n",
        "                for row in range(ksize):\n",
        "                    for col in range(ksize):\n",
        "                        sum += kernel[row,col]*padded_img[x - r + row, y - r + col, z]\n",
        "                final_img[i,j,k] = sum\n",
        "\n",
        "    return final_img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "266025a2-e74a-4bf3-9e94-dc6823f9bd64",
      "metadata": {
        "id": "266025a2-e74a-4bf3-9e94-dc6823f9bd64"
      },
      "source": [
        "Finally, we create a function which combines all the tasks and provides the final degraded image as the output. This takes the same inputs as described earlier for ***use_openCV*** function defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d3995a-f50a-4a40-b6a0-271149ecc901",
      "metadata": {
        "id": "09d3995a-f50a-4a40-b6a0-271149ecc901"
      },
      "outputs": [],
      "source": [
        "def use_myFunction(image, sigma, ksize):\n",
        "    kernel = get_gaussian_kernel_2d(ksize,sigma)             # get the gaussian kernel\n",
        "    blurred_img = convolve(image,kernel,ksize)                # perform convolution and get blurred image\n",
        "    final_img = add_gaussian_noise(blurred_img, sigma)       # finally add gaussian noise the blurred image\n",
        "\n",
        "    return final_img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1193fc-54c3-40cb-8ab6-d3eb1260a954",
      "metadata": {
        "id": "ce1193fc-54c3-40cb-8ab6-d3eb1260a954"
      },
      "source": [
        "Now, we define functions to calculate the MSE and MAE metrics for any given pair of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7abce52f-11fc-4d0f-aacc-0367d2e0129c",
      "metadata": {
        "id": "7abce52f-11fc-4d0f-aacc-0367d2e0129c"
      },
      "outputs": [],
      "source": [
        "def MSE(image1,image2):\n",
        "    mse = np.mean(np.square(image1.astype(float) - image2.astype(float)))\n",
        "    return mse\n",
        "\n",
        "def MAE(image1,image2):\n",
        "    mae = np.mean(np.abs(image1.astype(float) - image2.astype(float)))\n",
        "    return mae"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b362e17-3a2c-4ed2-a55b-6742b0b92c4a",
      "metadata": {
        "id": "3b362e17-3a2c-4ed2-a55b-6742b0b92c4a"
      },
      "source": [
        "Now, call the above functions to add noise to the images in the dataset, and compare how well do our functions match up against the functions in openCV. For computation purposes the size of the kernel is kept 9 at max(Meaning the maximum size of the kernel in any of these computations is 9*9).<br>\n",
        "The $\\sigma$ for gaussian noise and defocus blur increases from **5 to 25** the kernel size in increase from **3 to 11** across each image in the 5 variations of noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7961f930-9adf-4ef9-9859-4f45bc941cb1",
      "metadata": {
        "id": "7961f930-9adf-4ef9-9859-4f45bc941cb1"
      },
      "outputs": [],
      "source": [
        "test10 = use_myFunction(image1,5,3)\n",
        "test11 = use_openCV(image1,5,3)\n",
        "test12 = use_myFunction(image1,10,5)\n",
        "test13 = use_openCV(image1,10,5)\n",
        "test14 = use_myFunction(image1,15,7)\n",
        "test15 = use_openCV(image1,15,7)\n",
        "test16 = use_myFunction(image1,20,9)\n",
        "test17 = use_openCV(image1,20,9)\n",
        "test18 = use_myFunction(image1,25,11)\n",
        "test19 = use_openCV(image1,25,11)\n",
        "\n",
        "\n",
        "test20 = use_myFunction(image2,5,3)\n",
        "test21 = use_openCV(image2,5,3)\n",
        "test22 = use_myFunction(image2,10,5)\n",
        "test23 = use_openCV(image2,10,5)\n",
        "test24 = use_myFunction(image2,15,7)\n",
        "test25 = use_openCV(image2,15,7)\n",
        "test26 = use_myFunction(image2,20,9)\n",
        "test27 = use_openCV(image2,20,9)\n",
        "test28 = use_myFunction(image2,25,11)\n",
        "test29 = use_openCV(image2,25,11)\n",
        "\n",
        "\n",
        "test30 = use_myFunction(image3,5,3)\n",
        "test31 = use_openCV(image3,5,3)\n",
        "test32 = use_myFunction(image3,10,5)\n",
        "test33 = use_openCV(image3,10,5)\n",
        "test34 = use_myFunction(image3,15,7)\n",
        "test35 = use_openCV(image3,15,7)\n",
        "test36 = use_myFunction(image3,20,9)\n",
        "test37 = use_openCV(image3,20,9)\n",
        "test38 = use_myFunction(image3,25,11)\n",
        "test39 = use_openCV(image3,25,11)\n",
        "\n",
        "\n",
        "test40 = use_myFunction(image4,5,3)\n",
        "test41 = use_openCV(image4,5,3)\n",
        "test42 = use_myFunction(image4,10,5)\n",
        "test43 = use_openCV(image4,10,5)\n",
        "test44 = use_myFunction(image4,15,7)\n",
        "test45 = use_openCV(image4,15,7)\n",
        "test46 = use_myFunction(image4,20,9)\n",
        "test47 = use_openCV(image4,20,9)\n",
        "test48 = use_myFunction(image4,25,11)\n",
        "test49 = use_openCV(image4,25,11)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f9189f-1353-41ba-9e43-a0123b40542e",
      "metadata": {
        "id": "50f9189f-1353-41ba-9e43-a0123b40542e"
      },
      "outputs": [],
      "source": [
        "# Testing the outputs.\n",
        "print(\"Original Image:\")\n",
        "plot_image(image1)\n",
        "print(\"Using the function we defined:\")\n",
        "plot_image(test10)\n",
        "print(\"Using the OpenCV functions:\")\n",
        "plot_image(test11)\n",
        "print(\"Between the 2 noisy images, MSE: \" + str(MSE(test10,test11)) + \" and MAE: \" + str(MAE(test10,test11)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e6c6b2-cdac-42d6-b604-8590f0586436",
      "metadata": {
        "id": "b2e6c6b2-cdac-42d6-b604-8590f0586436"
      },
      "outputs": [],
      "source": [
        "print(\"Now MSE and MAE values for the noisy images produced by openCV and myFunction:\")\n",
        "print(\"Noisy variants of image1, MSE: \" + str(MSE(test10,test11)) + \" and MAE: \" + str(MAE(test10,test11)))\n",
        "print(\"Noisy variants of image2, MSE: \" + str(MSE(test20,test21)) + \" and MAE: \" + str(MAE(test20,test21)))\n",
        "print(\"Noisy variants of image3, MSE: \" + str(MSE(test30,test31)) + \" and MAE: \" + str(MAE(test30,test31)))\n",
        "print(\"Noisy variants of image4, MSE: \" + str(MSE(test40,test41)) + \" and MAE: \" + str(MAE(test40,test41)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15f546ea-75a3-494a-a606-a7c157b3060e",
      "metadata": {
        "id": "15f546ea-75a3-494a-a606-a7c157b3060e"
      },
      "source": [
        "We can clearly see that the image has been blurred and noise has been added, and that *myFunction* performs similar to the *OpenCV* functions. We also see that the *Mean Absolute Error(MAE)* is very small between the noisy versions of the image but the *Mean Square Error(MSE)* is higher than what you might expect."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1b6b06-c1f5-441d-bb50-67379f788dab",
      "metadata": {
        "id": "5f1b6b06-c1f5-441d-bb50-67379f788dab"
      },
      "source": [
        "The next cell of code can be collapsed and viewed using the clicking on the *View* on the menu above and selecting Expand/Collapse or Show/Hide the selected cells. The reason I have collapsed the code is that they are just arbitrary lines of code where I create a plot on the output using the matplotplotlib. Scroll in the ouput of the cell to see the entire result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3321b0db-4f49-4e25-b29d-bf20980a0604",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "scrolled": true,
        "cellView": "form",
        "id": "3321b0db-4f49-4e25-b29d-bf20980a0604"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "fig, axs = plt.subplots(20, 3, figsize=(16, 80))\n",
        "# Image1 with various noises\n",
        "axs[0, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 0].set_title('Original')\n",
        "axs[0, 1].imshow(cv2.cvtColor(test10, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 1].set_title('myFunc')\n",
        "axs[0, 2].imshow(cv2.cvtColor(test11, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 2].set_title('openCV')\n",
        "\n",
        "axs[1, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 0].set_title('Original')\n",
        "axs[1, 1].imshow(cv2.cvtColor(test12, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 1].set_title('myFunc')\n",
        "axs[1, 2].imshow(cv2.cvtColor(test13, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 2].set_title('openCV')\n",
        "\n",
        "axs[2, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 0].set_title('Original')\n",
        "axs[2, 1].imshow(cv2.cvtColor(test14, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 1].set_title('myFunc')\n",
        "axs[2, 2].imshow(cv2.cvtColor(test15, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 2].set_title('openCV')\n",
        "\n",
        "axs[3, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 0].set_title('Original')\n",
        "axs[3, 1].imshow(cv2.cvtColor(test16, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 1].set_title('myFunc')\n",
        "axs[3, 2].imshow(cv2.cvtColor(test17, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 2].set_title('openCV')\n",
        "\n",
        "axs[4, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[4, 0].set_title('Original')\n",
        "axs[4, 1].imshow(cv2.cvtColor(test18, cv2.COLOR_BGR2RGB))\n",
        "axs[4, 1].set_title('myFunc')\n",
        "axs[4, 2].imshow(cv2.cvtColor(test19, cv2.COLOR_BGR2RGB))\n",
        "axs[4, 2].set_title('openCV')\n",
        "\n",
        "# Image2 with various noises\n",
        "axs[5, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[5, 0].set_title('Original')\n",
        "axs[5, 1].imshow(cv2.cvtColor(test20, cv2.COLOR_BGR2RGB))\n",
        "axs[5, 1].set_title('myFunc')\n",
        "axs[5, 2].imshow(cv2.cvtColor(test21, cv2.COLOR_BGR2RGB))\n",
        "axs[5, 2].set_title('openCV')\n",
        "\n",
        "axs[6, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[6, 0].set_title('Original')\n",
        "axs[6, 1].imshow(cv2.cvtColor(test22, cv2.COLOR_BGR2RGB))\n",
        "axs[6, 1].set_title('myFunc')\n",
        "axs[6, 2].imshow(cv2.cvtColor(test23, cv2.COLOR_BGR2RGB))\n",
        "axs[6, 2].set_title('openCV')\n",
        "\n",
        "axs[7, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[7, 0].set_title('Original')\n",
        "axs[7, 1].imshow(cv2.cvtColor(test24, cv2.COLOR_BGR2RGB))\n",
        "axs[7, 1].set_title('myFunc')\n",
        "axs[7, 2].imshow(cv2.cvtColor(test25, cv2.COLOR_BGR2RGB))\n",
        "axs[7, 2].set_title('openCV')\n",
        "\n",
        "axs[8, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[8, 0].set_title('Original')\n",
        "axs[8, 1].imshow(cv2.cvtColor(test26, cv2.COLOR_BGR2RGB))\n",
        "axs[8, 1].set_title('myFunc')\n",
        "axs[8, 2].imshow(cv2.cvtColor(test27, cv2.COLOR_BGR2RGB))\n",
        "axs[8, 2].set_title('openCV')\n",
        "\n",
        "axs[9, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[9, 0].set_title('Original')\n",
        "axs[9, 1].imshow(cv2.cvtColor(test28, cv2.COLOR_BGR2RGB))\n",
        "axs[9, 1].set_title('myFunc')\n",
        "axs[9, 2].imshow(cv2.cvtColor(test29, cv2.COLOR_BGR2RGB))\n",
        "axs[9, 2].set_title('openCV')\n",
        "\n",
        "# Image3 with various noises\n",
        "axs[10, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[10, 0].set_title('Original')\n",
        "axs[10, 1].imshow(cv2.cvtColor(test30, cv2.COLOR_BGR2RGB))\n",
        "axs[10, 1].set_title('myFunc')\n",
        "axs[10, 2].imshow(cv2.cvtColor(test31, cv2.COLOR_BGR2RGB))\n",
        "axs[10, 2].set_title('openCV')\n",
        "\n",
        "axs[11, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[11, 0].set_title('Original')\n",
        "axs[11, 1].imshow(cv2.cvtColor(test32, cv2.COLOR_BGR2RGB))\n",
        "axs[11, 1].set_title('myFunc')\n",
        "axs[11, 2].imshow(cv2.cvtColor(test33, cv2.COLOR_BGR2RGB))\n",
        "axs[11, 2].set_title('openCV')\n",
        "\n",
        "axs[12, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[12, 0].set_title('Original')\n",
        "axs[12, 1].imshow(cv2.cvtColor(test34, cv2.COLOR_BGR2RGB))\n",
        "axs[12, 1].set_title('myFunc')\n",
        "axs[12, 2].imshow(cv2.cvtColor(test35, cv2.COLOR_BGR2RGB))\n",
        "axs[12, 2].set_title('openCV')\n",
        "\n",
        "axs[13, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[13, 0].set_title('Original')\n",
        "axs[13, 1].imshow(cv2.cvtColor(test36, cv2.COLOR_BGR2RGB))\n",
        "axs[13, 1].set_title('myFunc')\n",
        "axs[13, 2].imshow(cv2.cvtColor(test37, cv2.COLOR_BGR2RGB))\n",
        "axs[13, 2].set_title('openCV')\n",
        "\n",
        "axs[14, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[14, 0].set_title('Original')\n",
        "axs[14, 1].imshow(cv2.cvtColor(test38, cv2.COLOR_BGR2RGB))\n",
        "axs[14, 1].set_title('myFunc')\n",
        "axs[14, 2].imshow(cv2.cvtColor(test39, cv2.COLOR_BGR2RGB))\n",
        "axs[14, 2].set_title('openCV')\n",
        "\n",
        "# Image4 with various noises\n",
        "axs[15, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[15, 0].set_title('Original')\n",
        "axs[15, 1].imshow(cv2.cvtColor(test40, cv2.COLOR_BGR2RGB))\n",
        "axs[15, 1].set_title('myFunc')\n",
        "axs[15, 2].imshow(cv2.cvtColor(test41, cv2.COLOR_BGR2RGB))\n",
        "axs[15, 2].set_title('openCV')\n",
        "\n",
        "axs[16, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[16, 0].set_title('Original')\n",
        "axs[16, 1].imshow(cv2.cvtColor(test42, cv2.COLOR_BGR2RGB))\n",
        "axs[16, 1].set_title('myFunc')\n",
        "axs[16, 2].imshow(cv2.cvtColor(test43, cv2.COLOR_BGR2RGB))\n",
        "axs[16, 2].set_title('openCV')\n",
        "\n",
        "axs[17, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[17, 0].set_title('Original')\n",
        "axs[17, 1].imshow(cv2.cvtColor(test44, cv2.COLOR_BGR2RGB))\n",
        "axs[17, 1].set_title('myFunc')\n",
        "axs[17, 2].imshow(cv2.cvtColor(test45, cv2.COLOR_BGR2RGB))\n",
        "axs[17, 2].set_title('openCV')\n",
        "\n",
        "axs[18, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[18, 0].set_title('Original')\n",
        "axs[18, 1].imshow(cv2.cvtColor(test46, cv2.COLOR_BGR2RGB))\n",
        "axs[18, 1].set_title('myFunc')\n",
        "axs[18, 2].imshow(cv2.cvtColor(test47, cv2.COLOR_BGR2RGB))\n",
        "axs[18, 2].set_title('openCV')\n",
        "\n",
        "axs[19, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[19, 0].set_title('Original')\n",
        "axs[19, 1].imshow(cv2.cvtColor(test48, cv2.COLOR_BGR2RGB))\n",
        "axs[19, 1].set_title('myFunc')\n",
        "axs[19, 2].imshow(cv2.cvtColor(test49, cv2.COLOR_BGR2RGB))\n",
        "axs[19, 2].set_title('openCV')\n",
        "\n",
        "for ax in axs.ravel():\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c21aca74-b11e-4021-98b1-90553ec8ae4f",
      "metadata": {
        "id": "c21aca74-b11e-4021-98b1-90553ec8ae4f"
      },
      "source": [
        "Now, we define a function to create the wiener filter. The function takes the noisy image as kernel size, sigma, and 'K', the wiener parameter as the input. The wiener filter works accordint to the following formula\n",
        "$\\hat{f}(x, y) = H^*(x, y) \\cdot \\frac{1}{1 + \\frac{S_n(f)}{S_f(f)}} \\cdot G(u, v)$ <br>\n",
        "Here $\\frac{S_n(f)}{S_f(f)}$ is the wiener parameter and we denote it with k and vary it for real values of k. G(f) is the frequency domain representation of the noisy image, and it is computed using the fft ftunction in numpy. Similarly, H*(f) is also computed uisng the fft function on the gaussian kernel and then taking its complex conjugate. After computing the frquency domain representation of the image we take the inverse fourier transform and return the restored image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f68f8f40-0358-418a-bca1-b8c5c87d12ad",
      "metadata": {
        "id": "f68f8f40-0358-418a-bca1-b8c5c87d12ad"
      },
      "outputs": [],
      "source": [
        "def wiener_filter(noisy_img,ksize,sigma,k):\n",
        "    copy_img = noisy_img.copy()                # Create a copy of the noisy image\n",
        "    b, g, r = cv2.split(copy_img)              # Split the image into its color channels (BGR order)\n",
        "\n",
        "    # Normalize each channel to values from 0 to 1\n",
        "    r = cv2.normalize(r.astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "    g = cv2.normalize(g.astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "    b = cv2.normalize(b.astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "\n",
        "    # Get the gaussian kernel of the specified size\n",
        "    kernel = cv2.getGaussianKernel(ksize, sigma)\n",
        "\n",
        "    # Applying the wiener filter through the formula discussed above, for each of the 3 channels separately\n",
        "    R = np.fft.fft2(r)\n",
        "    H = np.fft.fft2(kernel,s=r.shape)\n",
        "    H = np.conj(H) / (np.abs(H)**2 + k)\n",
        "    R = R*H\n",
        "    R = np.abs(np.fft.ifft2(R))\n",
        "\n",
        "    G = np.fft.fft2(g)\n",
        "    H = np.fft.fft2(kernel,s=g.shape)\n",
        "    H = np.conj(H) / (np.abs(H)**2 + k)\n",
        "    G = G*H\n",
        "    G = np.abs(np.fft.ifft2(G))\n",
        "\n",
        "    B = np.fft.fft2(b)\n",
        "    H = np.fft.fft2(kernel,s=b.shape)\n",
        "    H = np.conj(H) / (np.abs(H)**2 + k)\n",
        "    B = B*H\n",
        "    B = np.abs(np.fft.ifft2(B))\n",
        "\n",
        "    # Merging the three channels to the required image.\n",
        "    merged_image = cv2.merge([B, G, R])\n",
        "    merged_image_final = np.clip(merged_image * 255, 0, 255).astype('uint8')\n",
        "\n",
        "    return merged_image_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e3e895-c4d9-4bdd-b319-843138fa27c9",
      "metadata": {
        "id": "b8e3e895-c4d9-4bdd-b319-843138fa27c9"
      },
      "source": [
        "Defining a function to compute the PSNR metric to compare the restored images with the original ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b48ba43-6539-4689-8dbe-83ed766aff58",
      "metadata": {
        "id": "0b48ba43-6539-4689-8dbe-83ed766aff58"
      },
      "outputs": [],
      "source": [
        "def PSNR(image1, image2, peak=255):\n",
        "    # Calculating the Mean Squared Error\n",
        "    mse = MSE(image1,image2)\n",
        "    # Calculating the Peak Signal Noise Ratio\n",
        "    psnr = 10*np.log10(peak**2/mse)\n",
        "\n",
        "    return psnr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5152ebbb-3499-479f-9f26-1eca6ba7bf3d",
      "metadata": {
        "id": "5152ebbb-3499-479f-9f26-1eca6ba7bf3d"
      },
      "source": [
        "Now, we restore the image using the wiener filter that we created. The values of k for each image was chosen after many trials and finally, the value which gave the highest PSNR value was chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb0c4ec-f2a7-4c26-a64a-ab1cf20e27b2",
      "metadata": {
        "id": "cfb0c4ec-f2a7-4c26-a64a-ab1cf20e27b2"
      },
      "outputs": [],
      "source": [
        "restored11 = wiener_filter(test11,3,5,0.04)\n",
        "restored13 = wiener_filter(test13,5,10,0.1)\n",
        "restored15 = wiener_filter(test15,7,15,0.1)\n",
        "restored17 = wiener_filter(test17,9,20,0.15)\n",
        "restored19 = wiener_filter(test19,11,25,0.15)\n",
        "\n",
        "restored21 = wiener_filter(test21,3,5,0.3)\n",
        "restored23 = wiener_filter(test23,5,10,0.5)\n",
        "restored25 = wiener_filter(test25,7,15,0.6)\n",
        "restored27 = wiener_filter(test27,9,20,0.8)\n",
        "restored29 = wiener_filter(test29,11,25,0.9)\n",
        "\n",
        "restored31 = wiener_filter(test31,3,5,0.3)\n",
        "restored33 = wiener_filter(test33,5,10,0.5)\n",
        "restored35 = wiener_filter(test35,7,15,0.7)\n",
        "restored37 = wiener_filter(test37,9,20,0.9)\n",
        "restored39 = wiener_filter(test39,11,25,0.8)\n",
        "\n",
        "restored41 = wiener_filter(test41,3,5,0.7)\n",
        "restored43 = wiener_filter(test43,5,10,0.9)\n",
        "restored45 = wiener_filter(test45,7,15,1.1)\n",
        "restored47 = wiener_filter(test47,9,20,1.3)\n",
        "restored49 = wiener_filter(test49,11,25,1.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28de8a2-8973-46bf-8927-579050c51e33",
      "metadata": {
        "id": "d28de8a2-8973-46bf-8927-579050c51e33"
      },
      "source": [
        "The next cell of code can be collapsed and viewed using the clicking on the *View* on the menu above and selecting Expand/Collapse or Show/Hide the selected cells. The reason I have collapsed the code is that they are just arbitrary lines of code where I create a plot on the output using the matplotplotlib.<br>\n",
        "Scroll in the ouput of the cell to see the entire result. The first column is the original image, second column is the noisy version of the image, and the third column is restored image which also shows the PSNR value, which is computed by calling the function we defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32348ae-fc81-4f73-b22f-9f38edfd8f7b",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "cellView": "form",
        "id": "b32348ae-fc81-4f73-b22f-9f38edfd8f7b"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "fig, axs = plt.subplots(20, 3, figsize=(16, 80))\n",
        "# Image1 with restoration\n",
        "axs[0, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 0].set_title('Original')\n",
        "axs[0, 1].imshow(cv2.cvtColor(test11, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 1].set_title('Noisy Image')\n",
        "axs[0, 2].imshow(cv2.cvtColor(restored11, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image1,restored11)))\n",
        "\n",
        "axs[1, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 0].set_title('Original')\n",
        "axs[1, 1].imshow(cv2.cvtColor(test13, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 1].set_title('Noisy Imgage')\n",
        "axs[1, 2].imshow(cv2.cvtColor(restored13, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image1,restored13)))\n",
        "\n",
        "axs[2, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 0].set_title('Original')\n",
        "axs[2, 1].imshow(cv2.cvtColor(test15, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 1].set_title('Noisy Imgage')\n",
        "axs[2, 2].imshow(cv2.cvtColor(restored15, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image1,restored15)))\n",
        "\n",
        "axs[3, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 0].set_title('Original')\n",
        "axs[3, 1].imshow(cv2.cvtColor(test17, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 1].set_title('Noisy Imgage')\n",
        "axs[3, 2].imshow(cv2.cvtColor(restored17, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image1,restored17)))\n",
        "\n",
        "axs[4, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[4, 0].set_title('Original')\n",
        "axs[4, 1].imshow(cv2.cvtColor(test19, cv2.COLOR_BGR2RGB))\n",
        "axs[4, 1].set_title('Noisy Imgage')\n",
        "axs[4, 2].imshow(cv2.cvtColor(restored19, cv2.COLOR_BGR2RGB))\n",
        "axs[4, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image1,restored19)))\n",
        "\n",
        "# Image2 with restoration\n",
        "axs[5, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[5, 0].set_title('Original')\n",
        "axs[5, 1].imshow(cv2.cvtColor(test21, cv2.COLOR_BGR2RGB))\n",
        "axs[5, 1].set_title('Noisy Image')\n",
        "axs[5, 2].imshow(cv2.cvtColor(restored21, cv2.COLOR_BGR2RGB))\n",
        "axs[5, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image2,restored21)))\n",
        "\n",
        "axs[6, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[6, 0].set_title('Original')\n",
        "axs[6, 1].imshow(cv2.cvtColor(test23, cv2.COLOR_BGR2RGB))\n",
        "axs[6, 1].set_title('Noisy Image')\n",
        "axs[6, 2].imshow(cv2.cvtColor(restored23, cv2.COLOR_BGR2RGB))\n",
        "axs[6, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image2,restored23)))\n",
        "\n",
        "axs[7, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[7, 0].set_title('Original')\n",
        "axs[7, 1].imshow(cv2.cvtColor(test25, cv2.COLOR_BGR2RGB))\n",
        "axs[7, 1].set_title('Noisy Image')\n",
        "axs[7, 2].imshow(cv2.cvtColor(restored25, cv2.COLOR_BGR2RGB))\n",
        "axs[7, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image2,restored25)))\n",
        "\n",
        "axs[8, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[8, 0].set_title('Original')\n",
        "axs[8, 1].imshow(cv2.cvtColor(test27, cv2.COLOR_BGR2RGB))\n",
        "axs[8, 1].set_title('Noisy Image')\n",
        "axs[8, 2].imshow(cv2.cvtColor(restored27, cv2.COLOR_BGR2RGB))\n",
        "axs[8, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image2,restored27)))\n",
        "\n",
        "axs[9, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[9, 0].set_title('Original')\n",
        "axs[9, 1].imshow(cv2.cvtColor(test29, cv2.COLOR_BGR2RGB))\n",
        "axs[9, 1].set_title('Noisy Image')\n",
        "axs[9, 2].imshow(cv2.cvtColor(restored29, cv2.COLOR_BGR2RGB))\n",
        "axs[9, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image2,restored29)))\n",
        "\n",
        "# Image3 with various noises\n",
        "axs[10, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[10, 0].set_title('Original')\n",
        "axs[10, 1].imshow(cv2.cvtColor(test31, cv2.COLOR_BGR2RGB))\n",
        "axs[10, 1].set_title('Noisy Image')\n",
        "axs[10, 2].imshow(cv2.cvtColor(restored31, cv2.COLOR_BGR2RGB))\n",
        "axs[10, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image3,restored31)))\n",
        "\n",
        "axs[11, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[11, 0].set_title('Original')\n",
        "axs[11, 1].imshow(cv2.cvtColor(test33, cv2.COLOR_BGR2RGB))\n",
        "axs[11, 1].set_title('Noisy Image')\n",
        "axs[11, 2].imshow(cv2.cvtColor(restored33, cv2.COLOR_BGR2RGB))\n",
        "axs[11, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image3,restored33)))\n",
        "\n",
        "axs[12, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[12, 0].set_title('Original')\n",
        "axs[12, 1].imshow(cv2.cvtColor(test35, cv2.COLOR_BGR2RGB))\n",
        "axs[12, 1].set_title('Noisy Image')\n",
        "axs[12, 2].imshow(cv2.cvtColor(restored35, cv2.COLOR_BGR2RGB))\n",
        "axs[12, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image3,restored35)))\n",
        "\n",
        "axs[13, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[13, 0].set_title('Original')\n",
        "axs[13, 1].imshow(cv2.cvtColor(test37, cv2.COLOR_BGR2RGB))\n",
        "axs[13, 1].set_title('Noisy Image')\n",
        "axs[13, 2].imshow(cv2.cvtColor(restored37, cv2.COLOR_BGR2RGB))\n",
        "axs[13, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image3,restored37)))\n",
        "\n",
        "axs[14, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[14, 0].set_title('Original')\n",
        "axs[14, 1].imshow(cv2.cvtColor(test39, cv2.COLOR_BGR2RGB))\n",
        "axs[14, 1].set_title('Noisy Image')\n",
        "axs[14, 2].imshow(cv2.cvtColor(restored39, cv2.COLOR_BGR2RGB))\n",
        "axs[14, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image3,restored39)))\n",
        "\n",
        "# Image4 with various noises\n",
        "axs[15, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[15, 0].set_title('Original')\n",
        "axs[15, 1].imshow(cv2.cvtColor(test41, cv2.COLOR_BGR2RGB))\n",
        "axs[15, 1].set_title('Noisy Image')\n",
        "axs[15, 2].imshow(cv2.cvtColor(restored41, cv2.COLOR_BGR2RGB))\n",
        "axs[15, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image4,restored41)))\n",
        "\n",
        "axs[16, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[16, 0].set_title('Original')\n",
        "axs[16, 1].imshow(cv2.cvtColor(test43, cv2.COLOR_BGR2RGB))\n",
        "axs[16, 1].set_title('Noisy Image')\n",
        "axs[16, 2].imshow(cv2.cvtColor(restored43, cv2.COLOR_BGR2RGB))\n",
        "axs[16, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image4,restored43)))\n",
        "\n",
        "axs[17, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[17, 0].set_title('Original')\n",
        "axs[17, 1].imshow(cv2.cvtColor(test45, cv2.COLOR_BGR2RGB))\n",
        "axs[17, 1].set_title('Noisy Image')\n",
        "axs[17, 2].imshow(cv2.cvtColor(restored45, cv2.COLOR_BGR2RGB))\n",
        "axs[17, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image4,restored45)))\n",
        "\n",
        "axs[18, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[18, 0].set_title('Original')\n",
        "axs[18, 1].imshow(cv2.cvtColor(test47, cv2.COLOR_BGR2RGB))\n",
        "axs[18, 1].set_title('Noisy Image')\n",
        "axs[18, 2].imshow(cv2.cvtColor(restored47, cv2.COLOR_BGR2RGB))\n",
        "axs[18, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image4,restored47)))\n",
        "\n",
        "axs[19, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[19, 0].set_title('Original')\n",
        "axs[19, 1].imshow(cv2.cvtColor(test49, cv2.COLOR_BGR2RGB))\n",
        "axs[19, 1].set_title('Noisy Image')\n",
        "axs[19, 2].imshow(cv2.cvtColor(restored49, cv2.COLOR_BGR2RGB))\n",
        "axs[19, 2].set_title(\"Restored, PSNR:\"+ str(PSNR(image4,restored49)))\n",
        "\n",
        "for ax in axs.ravel():\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for ax in axs.ravel():\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87bbdfd8-42b1-48b3-99d5-8f2e295e0b7e",
      "metadata": {
        "id": "87bbdfd8-42b1-48b3-99d5-8f2e295e0b7e"
      },
      "source": [
        "Now we will compare our restored versions of images, with different restoration algorithms, namely Non-local Means Filter,\n",
        "Total Variation Regularization, Bilateral Filter, Median Filter, Gaussian Smoothing Filter We will use the inbuilt functions of OpenCV/ Numpy to do this. ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ac32950-d341-4b2a-a77e-032d88f49a07",
      "metadata": {
        "id": "8ac32950-d341-4b2a-a77e-032d88f49a07"
      },
      "outputs": [],
      "source": [
        "def nlmeans(image, h = 10, template_size = 7, search_size = 21):\n",
        "    return cv2.fastNlMeansDenoising(image, None, h, template_size, search_size)\n",
        "\n",
        "def bilateral(image, diameter = 9, sigma_color = 75, sigma_space = 75):\n",
        "    return cv2.bilateralFilter(image, diameter, sigma_color, sigma_space)\n",
        "\n",
        "def median(image, kernel_size = 7):\n",
        "    return cv2.medianBlur(image, ksize)\n",
        "\n",
        "def gaussian(image, kernel_size = (7, 7), sigma_x = 0, sigma_y = 0):\n",
        "    return cv2.GaussianBlur(image, kernel_size, sigma_x, sigma_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fae070d-cb54-410c-b3d6-652c99d387a7",
      "metadata": {
        "id": "4fae070d-cb54-410c-b3d6-652c99d387a7"
      },
      "source": [
        "Now, we have to call the functions for these filters, and give the noisy images as inputs. For this I am choosing the noisy images for which $\\sigma$ is equal to 15 and the kernel size 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9523d2f2-05a7-41c9-980a-f85f152c65ac",
      "metadata": {
        "id": "9523d2f2-05a7-41c9-980a-f85f152c65ac"
      },
      "outputs": [],
      "source": [
        "nlmeans15 = nlmeans(test15)\n",
        "bilateral15 = bilateral(test15)\n",
        "median15 = median(test15)\n",
        "gaussian15 = nlmeans(test15)\n",
        "\n",
        "nlmeans25 = nlmeans(test25)\n",
        "bilateral25 = bilateral(test25)\n",
        "median25 = median(test25)\n",
        "gaussian25 = nlmeans(test25)\n",
        "\n",
        "nlmeans35 = nlmeans(test35)\n",
        "bilateral35 = bilateral(test35)\n",
        "median35 = median(test35)\n",
        "gaussian35 = nlmeans(test35)\n",
        "\n",
        "nlmeans45 = nlmeans(test45)\n",
        "bilateral45 = bilateral(test45)\n",
        "median45 = median(test45)\n",
        "gaussian45 = nlmeans(test45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b37b9b-a1fe-43ad-9a0f-bc2aade036ae",
      "metadata": {
        "cellView": "form",
        "id": "79b37b9b-a1fe-43ad-9a0f-bc2aade036ae"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "fig, axs = plt.subplots(4, 7, figsize=(49, 28))\n",
        "# Image1 with restoration\n",
        "axs[0, 0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 0].set_title('Original')\n",
        "axs[0, 1].imshow(cv2.cvtColor(test15, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 1].set_title('Noisy Image')\n",
        "axs[0, 2].imshow(cv2.cvtColor(restored15, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 2].set_title(\"Wiener, PSNR:\"+ str(PSNR(image1,restored15)))\n",
        "axs[0, 3].imshow(cv2.cvtColor(nlmeans15, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 3].set_title(\"Non-Local Means, PSNR:\"+ str(PSNR(image1,nlmeans15)))\n",
        "axs[0, 4].imshow(cv2.cvtColor(bilateral15, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 4].set_title(\"Bilateral, PSNR:\"+ str(PSNR(image1,bilateral15)))\n",
        "axs[0, 5].imshow(cv2.cvtColor(median15, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 5].set_title(\"Median, PSNR:\"+ str(PSNR(image1,median15)))\n",
        "axs[0, 6].imshow(cv2.cvtColor(gaussian15, cv2.COLOR_BGR2RGB))\n",
        "axs[0, 6].set_title(\"Gaussian , PSNR:\"+ str(PSNR(image1,gaussian15)))\n",
        "\n",
        "axs[1, 0].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 0].set_title('Original')\n",
        "axs[1, 1].imshow(cv2.cvtColor(test25, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 1].set_title('Noisy Image')\n",
        "axs[1, 2].imshow(cv2.cvtColor(restored25, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 2].set_title(\"Wiener, PSNR:\"+ str(PSNR(image2,restored25)))\n",
        "axs[1, 3].imshow(cv2.cvtColor(nlmeans25, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 3].set_title(\"Non-Local Means, PSNR:\"+ str(PSNR(image2,nlmeans25)))\n",
        "axs[1, 4].imshow(cv2.cvtColor(bilateral25, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 4].set_title(\"Bilateral, PSNR:\"+ str(PSNR(image2,bilateral25)))\n",
        "axs[1, 5].imshow(cv2.cvtColor(median25, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 5].set_title(\"Median, PSNR:\"+ str(PSNR(image2,median25)))\n",
        "axs[1, 6].imshow(cv2.cvtColor(gaussian25, cv2.COLOR_BGR2RGB))\n",
        "axs[1, 6].set_title(\"Gaussian , PSNR:\"+ str(PSNR(image2,gaussian25)))\n",
        "\n",
        "axs[2, 0].imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 0].set_title('Original')\n",
        "axs[2, 1].imshow(cv2.cvtColor(test35, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 1].set_title('Noisy Image')\n",
        "axs[2, 2].imshow(cv2.cvtColor(restored35, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 2].set_title(\"Wiener, PSNR:\"+ str(PSNR(image3,restored35)))\n",
        "axs[2, 3].imshow(cv2.cvtColor(nlmeans35, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 3].set_title(\"Non-Local Means, PSNR:\"+ str(PSNR(image3,nlmeans35)))\n",
        "axs[2, 4].imshow(cv2.cvtColor(bilateral35, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 4].set_title(\"Bilateral, PSNR:\"+ str(PSNR(image3,bilateral35)))\n",
        "axs[2, 5].imshow(cv2.cvtColor(median35, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 5].set_title(\"Median, PSNR:\"+ str(PSNR(image3,median35)))\n",
        "axs[2, 6].imshow(cv2.cvtColor(gaussian35, cv2.COLOR_BGR2RGB))\n",
        "axs[2, 6].set_title(\"Gaussian , PSNR:\"+ str(PSNR(image3,gaussian35)))\n",
        "\n",
        "axs[3, 0].imshow(cv2.cvtColor(image4, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 0].set_title('Original')\n",
        "axs[3, 1].imshow(cv2.cvtColor(test45, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 1].set_title('Noisy Image')\n",
        "axs[3, 2].imshow(cv2.cvtColor(restored45, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 2].set_title(\"Wiener, PSNR:\"+ str(PSNR(image4,restored45)))\n",
        "axs[3, 3].imshow(cv2.cvtColor(nlmeans45, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 3].set_title(\"Non-Local Means, PSNR:\"+ str(PSNR(image4,nlmeans45)))\n",
        "axs[3, 4].imshow(cv2.cvtColor(bilateral45, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 4].set_title(\"Bilateral, PSNR:\"+ str(PSNR(image4,bilateral45)))\n",
        "axs[3, 5].imshow(cv2.cvtColor(median45, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 5].set_title(\"Median, PSNR:\"+ str(PSNR(image4,median45)))\n",
        "axs[3, 6].imshow(cv2.cvtColor(gaussian45, cv2.COLOR_BGR2RGB))\n",
        "axs[3, 6].set_title(\"Gaussian , PSNR:\"+ str(PSNR(image4,gaussian45)))\n",
        "\n",
        "for ax in axs.ravel():\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for ax in axs.ravel():\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0117df13-9f80-45d8-a334-79770954c48a",
      "metadata": {
        "id": "0117df13-9f80-45d8-a334-79770954c48a"
      },
      "source": [
        "(If the output is appearing as tiny images, double click/click once on the output section. The images are now enlarged and can be viewed by scrolling sideways and downwards.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31709ac1-cb28-4d4d-bf67-6235cc0338cb",
      "metadata": {
        "id": "31709ac1-cb28-4d4d-bf67-6235cc0338cb"
      },
      "source": [
        "# Conclusion:\n",
        "- Successfully implemented the Wiener filter from scratch for image restoration.\n",
        "-\n",
        "Achieved PSNR values ranging from 12 to 17 for most cases, indicating the effectiveness of the restoration\n",
        "- Comparative analysis showed that the implemented Wiener filter performs at par, if not better as compared to Non-local Means, Bilateral, and Gaussian Smoothing filters in almost all scenarios.\n",
        "- Exceptional performance of the Median Filter was noted, surpassing all other filters in generating higher quality outputs.\n",
        "- The conclusions drawn are substantiated by the clear PSNR values obtained for each filter, providing a quantitative measure of image quality.ity."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}